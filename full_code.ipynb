{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T13:32:17.487704Z",
     "iopub.status.busy": "2024-09-16T13:32:17.487342Z",
     "iopub.status.idle": "2024-09-16T13:32:17.499820Z",
     "shell.execute_reply": "2024-09-16T13:32:17.498941Z",
     "shell.execute_reply.started": "2024-09-16T13:32:17.487671Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Definicja etykiet emocji\n",
    "emotion_labels = ['Neutral', 'Happiness', 'Sadness', 'Surprise', 'Fear', 'Disgust', 'Anger']\n",
    "\n",
    "# Sprawdzenie dostępności GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Ustawienie ścieżek\n",
    "data_path = \"/kaggle/input/raf-db-zmienione-labele\"\n",
    "train_dir = os.path.join(data_path, \"train\")\n",
    "test_dir = os.path.join(data_path, \"test\")\n",
    "\n",
    "# Konfiguracja parametrów\n",
    "num_classes = len(emotion_labels)\n",
    "batch_size = 64\n",
    "num_epochs = 20\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "\n",
    "# Normalizacja obrazów\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# Przygotowanie transformacji dla danych\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T13:32:17.502316Z",
     "iopub.status.busy": "2024-09-16T13:32:17.501984Z",
     "iopub.status.idle": "2024-09-16T13:32:18.101859Z",
     "shell.execute_reply": "2024-09-16T13:32:18.100766Z",
     "shell.execute_reply.started": "2024-09-16T13:32:17.502282Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LocalFeatureExtractor(nn.Module):\n",
    "    def __init__(self, inplanes, planes):\n",
    "        super(LocalFeatureExtractor, self).__init__()\n",
    "        self.conv1_1 = nn.Conv2d(inplanes, inplanes, kernel_size=3, stride=2, padding=1, groups=inplanes, bias=False)\n",
    "        self.bn1_1 = nn.BatchNorm2d(inplanes)\n",
    "        self.conv1_2 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn1_2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.conv2_1 = nn.Conv2d(inplanes, inplanes, kernel_size=3, stride=2, padding=1, groups=inplanes, bias=False)\n",
    "        self.bn2_1 = nn.BatchNorm2d(inplanes)\n",
    "        self.conv2_2 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn2_2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.conv3_1 = nn.Conv2d(inplanes, inplanes, kernel_size=3, stride=2, padding=1, groups=inplanes, bias=False)\n",
    "        self.bn3_1 = nn.BatchNorm2d(inplanes)\n",
    "        self.conv3_2 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn3_2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.conv4_1 = nn.Conv2d(inplanes, inplanes, kernel_size=3, stride=2, padding=1, groups=inplanes, bias=False)\n",
    "        self.bn4_1 = nn.BatchNorm2d(inplanes)\n",
    "        self.conv4_2 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn4_2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        patch_11 = x[:, :, 0:28, 0:28]\n",
    "        patch_21 = x[:, :, 28:56, 0:28]\n",
    "        patch_12 = x[:, :, 0:28, 28:56]\n",
    "        patch_22 = x[:, :, 28:56, 28:56]\n",
    "\n",
    "        out_1 = self.relu(self.bn1_2(self.conv1_2(self.relu(self.bn1_1(self.conv1_1(patch_11))))))\n",
    "        out_2 = self.relu(self.bn2_2(self.conv2_2(self.relu(self.bn2_1(self.conv2_1(patch_21))))))\n",
    "        out_3 = self.relu(self.bn3_2(self.conv3_2(self.relu(self.bn3_1(self.conv3_1(patch_12))))))\n",
    "        out_4 = self.relu(self.bn4_2(self.conv4_2(self.relu(self.bn4_1(self.conv4_1(patch_22))))))\n",
    "\n",
    "        out1 = torch.cat([out_1, out_2], dim=2)\n",
    "        out2 = torch.cat([out_3, out_4], dim=2)\n",
    "        out = torch.cat([out1, out2], dim=3)\n",
    "\n",
    "        return out\n",
    "\n",
    "# Implementacja mechanizmu uwagi\n",
    "class AttentionModule(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(AttentionModule, self).__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels // 16, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels // 16, in_channels, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        attention_weights = self.attention(x)\n",
    "        return x * attention_weights\n",
    "\n",
    "# Hybrydowy model EfficientFace-ResNet\n",
    "class EfficientFaceResNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(EfficientFaceResNet, self).__init__()\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        self.local_feature_extractor = LocalFeatureExtractor(3, 116)\n",
    "        self.attention1 = AttentionModule(256)\n",
    "        self.attention2 = AttentionModule(512)\n",
    "        self.attention3 = AttentionModule(1024)\n",
    "        self.attention4 = AttentionModule(2048)\n",
    "        \n",
    "        # Dodajemy warstwę konwolucyjną do dostosowania wymiarów cech lokalnych\n",
    "        self.local_feature_adapter = nn.Conv2d(116, 2048, kernel_size=1)\n",
    "        \n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Local Feature Extractor\n",
    "        local_features = self.local_feature_extractor(x)\n",
    "\n",
    "        # ResNet layers with attention\n",
    "        x = self.resnet.conv1(x)\n",
    "        x = self.resnet.bn1(x)\n",
    "        x = self.resnet.relu(x)\n",
    "        x = self.resnet.maxpool(x)\n",
    "\n",
    "        x = self.resnet.layer1(x)\n",
    "        x = self.attention1(x)\n",
    "\n",
    "        x = self.resnet.layer2(x)\n",
    "        x = self.attention2(x)\n",
    "\n",
    "        x = self.resnet.layer3(x)\n",
    "        x = self.attention3(x)\n",
    "\n",
    "        x = self.resnet.layer4(x)\n",
    "        x = self.attention4(x)\n",
    "\n",
    "        # Dostosuj wymiary cech lokalnych i połącz z cechami globalnymi\n",
    "        adapted_local_features = self.local_feature_adapter(local_features)\n",
    "        adapted_local_features = F.interpolate(adapted_local_features, size=x.size()[2:], mode='bilinear', align_corners=False)\n",
    "        x = x + adapted_local_features\n",
    "\n",
    "        x = self.resnet.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Inicjalizacja modelu\n",
    "model = EfficientFaceResNet(num_classes=7).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T13:32:18.103986Z",
     "iopub.status.busy": "2024-09-16T13:32:18.103622Z",
     "iopub.status.idle": "2024-09-16T13:32:25.483289Z",
     "shell.execute_reply": "2024-09-16T13:32:25.482530Z",
     "shell.execute_reply.started": "2024-09-16T13:32:18.103951Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Wczytanie danych treningowych i testowych\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transform)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=test_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "# Wyświetlenie przykładowych obrazów\n",
    "def show_samples(dataset, num_samples=7):\n",
    "    fig, axes = plt.subplots(1, num_samples, figsize=(15, 3))\n",
    "    for i in range(num_samples):\n",
    "        idx = np.random.randint(len(dataset))\n",
    "        img, label = dataset[idx]\n",
    "        img = img.permute(1, 2, 0).numpy()\n",
    "        img = (img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])).clip(0, 1)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(emotion_labels[label])\n",
    "        axes[i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "print(\"Przykładowe obrazy treningowe:\")\n",
    "show_samples(train_dataset)\n",
    "print(\"Przykładowe obrazy testowe:\")\n",
    "show_samples(test_dataset)\n",
    "\n",
    "# Inicjalizacja modelu\n",
    "model = model.to(device)\n",
    "\n",
    "# Inicjalizacja kryterium straty i optymalizatora\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T13:32:25.485840Z",
     "iopub.status.busy": "2024-09-16T13:32:25.485529Z",
     "iopub.status.idle": "2024-09-16T13:32:25.501975Z",
     "shell.execute_reply": "2024-09-16T13:32:25.501262Z",
     "shell.execute_reply.started": "2024-09-16T13:32:25.485808Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model ...')\n",
    "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "class LRScheduler:\n",
    "    def __init__(self, optimizer, patience=5, min_lr=1e-6, factor=0.5):\n",
    "        self.optimizer = optimizer\n",
    "        self.patience = patience\n",
    "        self.min_lr = min_lr\n",
    "        self.factor = factor\n",
    "        self.lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau( \n",
    "                self.optimizer,\n",
    "                mode='min',\n",
    "                patience=self.patience,\n",
    "                factor=self.factor,\n",
    "                min_lr=self.min_lr,\n",
    "                verbose=True\n",
    "            )\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        self.lr_scheduler.step(val_loss)\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T13:32:25.503783Z",
     "iopub.status.busy": "2024-09-16T13:32:25.503079Z",
     "iopub.status.idle": "2024-09-16T13:32:25.521051Z",
     "shell.execute_reply": "2024-09-16T13:32:25.520271Z",
     "shell.execute_reply.started": "2024-09-16T13:32:25.503737Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        acc1, = accuracy(outputs, targets, topk=(1,))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return losses.avg, top1.avg\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_loader:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            acc1, = accuracy(outputs, targets, topk=(1,))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "\n",
    "    return losses.avg, top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T13:32:25.522597Z",
     "iopub.status.busy": "2024-09-16T13:32:25.522048Z",
     "iopub.status.idle": "2024-09-16T14:31:34.268324Z",
     "shell.execute_reply": "2024-09-16T14:31:34.267101Z",
     "shell.execute_reply.started": "2024-09-16T13:32:25.522565Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=10, verbose=True)\n",
    "lr_scheduler = LRScheduler(optimizer)\n",
    "\n",
    "# Listy do przechowywania wyników\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    \n",
    "    # Trening\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    train_losses.append(float(train_loss))  # Konwersja na float, jeśli to tensor\n",
    "    train_accuracies.append(float(train_acc))\n",
    "    \n",
    "    val_loss, val_acc = validate(model, test_loader, criterion, device)\n",
    "    val_losses.append(float(val_loss))  # Konwersja na float, jeśli to tensor\n",
    "    val_accuracies.append(float(val_acc))\n",
    "    \n",
    "    # Wydruk wyników\n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "    print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "    \n",
    "    # Aktualizacja learning rate\n",
    "    lr_scheduler(val_loss)\n",
    "    \n",
    "    # Zapisywanie najlepszego modelu\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(f'New best model saved with validation accuracy: {best_val_acc:.2f}%')\n",
    "    \n",
    "    # Early stopping\n",
    "    early_stopping(val_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "# Wczytanie najlepszego modelu\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Ewaluacja na zbiorze testowym\n",
    "model.eval()\n",
    "test_loss, test_acc = validate(model, test_loader, criterion, device)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%')\n",
    "\n",
    "# Macierz pomyłek\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# Zapisywanie modelu\n",
    "torch.save(model.state_dict(), 'efficient_face_raf_db.pth')\n",
    "print(\"Model został zapisany.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T14:31:34.270405Z",
     "iopub.status.busy": "2024-09-16T14:31:34.270032Z",
     "iopub.status.idle": "2024-09-16T14:31:34.963245Z",
     "shell.execute_reply": "2024-09-16T14:31:34.962396Z",
     "shell.execute_reply.started": "2024-09-16T14:31:34.270364Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T14:31:34.965373Z",
     "iopub.status.busy": "2024-09-16T14:31:34.964662Z",
     "iopub.status.idle": "2024-09-16T14:32:03.741110Z",
     "shell.execute_reply": "2024-09-16T14:32:03.740126Z",
     "shell.execute_reply.started": "2024-09-16T14:31:34.965318Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss, test_acc = validate(model, test_loader, criterion, device)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%')\n",
    "\n",
    "# Macierz pomyłek\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=emotion_labels, yticklabels=emotion_labels)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T14:32:03.745419Z",
     "iopub.status.busy": "2024-09-16T14:32:03.744974Z",
     "iopub.status.idle": "2024-09-16T14:32:04.279738Z",
     "shell.execute_reply": "2024-09-16T14:32:04.278693Z",
     "shell.execute_reply.started": "2024-09-16T14:32:03.745379Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Zapisywanie całego modelu\n",
    "torch.save(model, 'efficient_face_full_model.pth')\n",
    "\n",
    "# Zapisywanie tylko stanu modelu (zalecane)\n",
    "torch.save(model.state_dict(), 'efficient_face_state_dict.pth')\n",
    "\n",
    "print(\"Model został zapisany.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5670231,
     "sourceId": 9353702,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5714747,
     "sourceId": 9414413,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 196897911,
     "sourceType": "kernelVersion"
    },
    {
     "modelId": 120451,
     "modelInstanceId": 96269,
     "sourceId": 114649,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
